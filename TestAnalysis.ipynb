{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994d88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "from ipyparallel import Client, parallel, require\n",
    "\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafde494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class poseDetector():\n",
    "\n",
    "    def __init__(self, mode=False, upBody=False, smooth=True,\n",
    "                 detectionCon=0.5, trackCon=0.5):\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.upBody = upBody\n",
    "\n",
    "        self.smooth = smooth\n",
    "\n",
    "        self.detectionCon = detectionCon\n",
    "\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "        self.mpPose = mp.solutions.pose\n",
    "# test diff values of this param for robustness, maybe always remove first and last peaks\n",
    "        self.pose =self.mpPose.Pose(model_complexity=2,smooth_landmarks = True,min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5)# self.mpPose.Pose(~self.mode, self.upBody, self.smooth,     self.detectionCon, self.trackCon~)\n",
    "\n",
    "    def findPose(self, img, draw=True):   # THIS draw is responsible for drawing stick figure\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        self.results = self.pose.process(imgRGB)\n",
    "        # print(self.results)\n",
    "        if self.results.pose_landmarks:\n",
    "            if draw:\n",
    "                # print(self.results.pose_landmarks,self.mpPose.POSE_CONNECTIONS)\n",
    "                self.mpDraw.draw_landmarks(img, self.results.pose_landmarks,\n",
    "                                           self.mpPose.POSE_CONNECTIONS)\n",
    "        # print(\"pose worls landmarks\")\n",
    "        # self.mpDraw.plot_landmarks(\n",
    "        # self.results.pose_world_landmarks, self.mpPose.POSE_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def findPosition(self, img, draw=True):\n",
    "        font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale              = .5\n",
    "        fontColor              = (255,255,255)\n",
    "        thickness              = 2\n",
    "        lineType               = 2\n",
    "        self.lmList = []\n",
    "\n",
    "        if self.results.pose_landmarks:\n",
    "\n",
    "            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
    "\n",
    "                h, w, c = img.shape\n",
    "                \n",
    "                if lm.visibility <.3:\n",
    "                    lm.x=lm.y=lm.z=-1\n",
    "#                 print(id, \" = \",lm.visibility)\n",
    "                # if id == 25:\n",
    "                #     print(id, lm)\n",
    "                cx, cy, cz = int(lm.x * w), int(lm.y * h), int(lm.z * w)\n",
    "\n",
    "                self.lmList.append([id, lm.x, lm.y, lm.z])\n",
    "\n",
    "                if draw:\n",
    "                    cv2.putText(img,str(id),    (cx,cy),     font,     fontScale,    fontColor,    thickness,    lineType)\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "        return self.lmList\n",
    "detector=poseDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e786be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time.time()\n",
    "frame=cv2.imread('./TestAnalysis/Capture.jpg')\n",
    "detector = poseDetector()\n",
    "img = detector.findPose(frame)\n",
    "cv2.imshow(\"\",img)\n",
    "cv2.waitKey(0)\n",
    "lmList = detector.findPosition(img, draw=True)\n",
    "print(time.time()-tic)\n",
    "\n",
    "for value in lmList:\n",
    "    if(value[1]==-1):\n",
    "        print(value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786fc99",
   "metadata": {},
   "source": [
    "## Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1368d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('T1.mp4')\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a610de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time.time()\n",
    "i=0\n",
    "cap = cv2.VideoCapture('T2.mp4')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    i += 1\n",
    "    cv2.imwrite(f'./TestAnalysis/T2/frame_{i}.jpg', frame)\n",
    "cap.release()\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf7b86",
   "metadata": {},
   "source": [
    "## Frame Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20596bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "35.632554054260254\n"
     ]
    }
   ],
   "source": [
    "tic=time.time()\n",
    "folder_path = './TestAnalysis/T1'\n",
    "file_list =(os.listdir(folder_path))\n",
    "sorted_file_list = sorted(file_list, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "t1_frames=[]\n",
    "for frame in sorted_file_list[:1000]:\n",
    "    frame=cv2.imread('./TestAnalysis/T1/'+frame)\n",
    "    t1_frames.append(frame)\n",
    "print(len(t1_frames))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5202b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInteresting(frame):\n",
    "    \n",
    "    # Load YOLOv3 network\n",
    "    net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "    # Get the output layer names\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # Load the image\n",
    "    image = frame\n",
    "    # Resize and normalize the image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    # Set the blob as input to the network\n",
    "    net.setInput(blob)\n",
    "    # Perform forward pass and get output\n",
    "    outputs = net.forward(output_layers)\n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    # Set confidence threshold and non-maximum suppression threshold\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "    # Iterate over each output layer\n",
    "    for output in outputs:\n",
    "        # Iterate over each detection\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # Filter detections by class (person)\n",
    "            if class_id == 0 and confidence > conf_threshold:\n",
    "                # Scale the bounding box coordinates to the original image size\n",
    "                width, height = image.shape[1], image.shape[0]\n",
    "                x, y, w, h = detection[:4] * np.array([width, height, width, height])\n",
    "                x_min, y_min = int(x - w / 2), int(y - h / 2)\n",
    "                # Add bounding box, confidence, and class ID to respective lists\n",
    "                boxes.append([x_min, y_min, int(w), int(h)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    # Apply non-maximum suppression to eliminate overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    b=False\n",
    "    num_persons=len(indices)\n",
    "#     print('boxes: ',(boxes))\n",
    "#     for i in range(len(indices)):\n",
    "#         x1, y1, w1, h1 = boxes[indices[i]]\n",
    "#         label = f\"Person {i+1}\"\n",
    "#         cv2.rectangle(image, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "#         cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "#     cv2.imwrite('./check.jpg',frame)\n",
    "    for i in range(len(indices)):\n",
    "        if(b):\n",
    "            break\n",
    "        x1, y1, w1, h1 = boxes[indices[i]]\n",
    "        center_x1 = x1 + w1 / 2\n",
    "        center_y1 = y1 + h1 / 2    \n",
    "        for j in range(i+1, len(indices)):\n",
    "            x2, y2, w2, h2 = boxes[indices[j]]\n",
    "            # Calculate the center coordinates of box j\n",
    "            center_x2 = x2 + w2 / 2\n",
    "            center_y2 = y2 + h2 / 2\n",
    "            # Calculate the distances between the centers of box i and box j\n",
    "            x_distance = abs(center_x1 - center_x2)\n",
    "            y_distance = abs(center_y1 - center_y2)\n",
    "#             print(f\"Distance: Person {i+1} and Person {j+1}: {x_distance}, {y_distance}\")\n",
    "            if(x_distance<22 and y_distance>=300 and y_distance<=400):\n",
    "                cv2.rectangle(image, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "                cv2.rectangle(image, (x2, y2), (x2 + w2, y2 + h2), (255, 0, 0), 2)\n",
    "                b=True\n",
    "                break\n",
    "    if(b and num_persons>=4 and num_persons<=9):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b60655",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time.time()\n",
    "i=0\n",
    "idx=0\n",
    "while(idx<500):\n",
    "    i+=1\n",
    "    frame=t1_frames[idx]\n",
    "    if(isInteresting(frame)):\n",
    "        for k in range(30):\n",
    "            cv2.imwrite(f'./TestAnalysis/Check/frame_{i}.jpg',frame)\n",
    "            i+=1\n",
    "            idx+=1\n",
    "            frame=t1_frames[idx]\n",
    "    idx+=1\n",
    "print('Time to store frames: ',time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './TestAnalysis/cropped/'\n",
    "file_list =(os.listdir(folder_path))\n",
    "sorted_file_list = sorted(file_list, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "crop_frames=[]\n",
    "for frame in sorted_file_list:\n",
    "    f=cv2.imread(folder_path+frame)\n",
    "    crop_frames.append(f)\n",
    "print(len(crop_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b915614",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "i=0\n",
    "for frame in check_frames[:50]:\n",
    "    h,_,_=frame.shape\n",
    "    mid=h//2\n",
    "    top=frame[:mid,:] # saving particular width frame\n",
    "    cv2.imshow('',top)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    booli=input()\n",
    "    if(booli=='y'):\n",
    "        detector=poseDetector()\n",
    "        img = detector.findPose(top)\n",
    "        lmList = detector.findPosition(img, draw=True)\n",
    "        cv2.imshow('',img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        normalized_vectors = []\n",
    "        for pt in lmList:\n",
    "            normalized_vectors.append(( pt[1], pt[2], pt[3]))\n",
    "        dic[i] = normalized_vectors\n",
    "        i+=1\n",
    "    elif(booli=='n'):\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "#     detector = poseDetector()\n",
    "#     img = detector.findPose(frame)\n",
    "#     cv2.imshow('',img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     lmList = detector.findPosition(img, draw=True)\n",
    "#     normalized_vectors = []\n",
    "#     for pt in lmList:\n",
    "#         normalized_vectors.append(( pt[1], pt[2], pt[3]))\n",
    "#     dic[i] = normalized_vectors\n",
    "#     i = i + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18545b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time.time()\n",
    "i=0\n",
    "dic={}\n",
    "for frame in crop_frames:\n",
    "    detector=poseDetector()\n",
    "    img = detector.findPose(frame)\n",
    "    lmList = detector.findPosition(img, draw=True)\n",
    "    cv2.imshow('',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    normalized_vectors = []\n",
    "    for pt in lmList:\n",
    "        normalized_vectors.append(( pt[1], pt[2], pt[3]))\n",
    "    dic[i] = normalized_vectors\n",
    "    i+=1\n",
    "\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9989688",
   "metadata": {},
   "source": [
    "## Getting coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('t2.webm')\n",
    "# Callback function for mouse events\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        print(f\"Coordinates: ({x}, {y})\")\n",
    "\n",
    "# Create a named window and set the callback function\n",
    "cv2.namedWindow(\"Frame\")\n",
    "# cv2.resizeWindow(\"Frame\", 800, 600)\n",
    "\n",
    "cv2.setMouseCallback(\"Frame\", mouse_callback)\n",
    "# cv2.imshow(\"Frame\", frame)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526eab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frames.append(frame)\n",
    "    if(len(frames)>100):\n",
    "        break\n",
    "cap.release()\n",
    "i=0\n",
    "for frame in frames[96:]:\n",
    "    cv2.imwrite(f'./{i}.jpg',frame)\n",
    "    i+=1\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5289153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame length: 150\n"
     ]
    }
   ],
   "source": [
    "folder_path = './TestAnalysis/Check/'\n",
    "file_list =(os.listdir(folder_path))\n",
    "sorted_file_list = sorted(file_list, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "frames=[]\n",
    "\n",
    "top_left = (500, 100)\n",
    "top_right = (1026, 90)\n",
    "bottom_right = (751, 500)\n",
    "bottom_left = (774, 345)\n",
    "\n",
    "for file in sorted_file_list:\n",
    "    frame=cv2.imread(folder_path+file)\n",
    "    cropped_image = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "    frames.append(cropped_image)\n",
    "#     cv2.imshow('Frame',cropped_image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.imwrite('./Cropped_Image.jpg', cropped_image)\n",
    "print('frame length:',len(frames))\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ea7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "i=0\n",
    "for frame in frames:\n",
    "    img = detector.findPose(frame)\n",
    "    lmList = detector.findPosition(img, draw=True)\n",
    "    cv2.imshow('',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    normalized_vectors = []\n",
    "    for pt in lmList:\n",
    "        normalized_vectors.append(( pt[1], pt[2], pt[3]))\n",
    "    dic[i]=normalized_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf9cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
