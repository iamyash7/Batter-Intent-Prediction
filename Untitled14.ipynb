{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInteresting(frame):\n",
    "    \n",
    "    # Load YOLOv3 network\n",
    "    net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "    # Get the output layer names\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # Load the image\n",
    "    image = frame\n",
    "    # Resize and normalize the image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    # Set the blob as input to the network\n",
    "    net.setInput(blob)\n",
    "    # Perform forward pass and get output\n",
    "    outputs = net.forward(output_layers)\n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    # Set confidence threshold and non-maximum suppression threshold\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "    # Iterate over each output layer\n",
    "    for output in outputs:\n",
    "        # Iterate over each detection\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # Filter detections by class (person)\n",
    "            if class_id == 0 and confidence > conf_threshold:\n",
    "                # Scale the bounding box coordinates to the original image size\n",
    "                width, height = image.shape[1], image.shape[0]\n",
    "                x, y, w, h = detection[:4] * np.array([width, height, width, height])\n",
    "                x_min, y_min = int(x - w / 2), int(y - h / 2)\n",
    "                # Add bounding box, confidence, and class ID to respective lists\n",
    "                boxes.append([x_min, y_min, int(w), int(h)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    # Apply non-maximum suppression to eliminate overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    b=False\n",
    "    num_persons=len(indices)\n",
    "    print('boxes: ',(boxes))\n",
    "    for i in range(len(indices)):\n",
    "        if(b):\n",
    "            break\n",
    "        x1, y1, w1, h1 = boxes[indices[i]]\n",
    "        center_x1 = x1 + w1 / 2\n",
    "        center_y1 = y1 + h1 / 2    \n",
    "        for j in range(i+1, len(indices)):\n",
    "            x2, y2, w2, h2 = boxes[indices[j]]\n",
    "            # Calculate the center coordinates of box j\n",
    "            center_x2 = x2 + w2 / 2\n",
    "            center_y2 = y2 + h2 / 2\n",
    "            # Calculate the distances between the centers of box i and box j\n",
    "            x_distance = abs(center_x1 - center_x2)\n",
    "            y_distance = abs(center_y1 - center_y2)\n",
    "            print(x_distance,' ',y_distance)\n",
    "            if(x_distance<22 and y_distance>=300 and y_distance<=400):\n",
    "                _,_,_,h=boxes[indices[i]]\n",
    "                _,_,_,h1=boxes[indices[j]]\n",
    "                if(h>h2):\n",
    "                    cord=boxes[indices[i]]\n",
    "                else:\n",
    "                    cord=boxes[indices[j]]\n",
    "                b=True\n",
    "                break\n",
    "    if(b and num_persons>=4 and num_persons<=7):\n",
    "        return True,cord\n",
    "    return False,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-45d42bf250b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misInteresting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cd88f1cf39fd>\u001b[0m in \u001b[0;36misInteresting\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Perform forward pass and get output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Initialize lists for bounding boxes, confidences, and class IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import yt_dlp\n",
    "import os\n",
    "tic=time.time()\n",
    "\n",
    "index=[]\n",
    "file='v1.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(file)\n",
    "i=0\n",
    "\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if(isInteresting(frame)):\n",
    "        k=0\n",
    "        index.append(i)\n",
    "        while(k<25):\n",
    "            frame_name = f\"frame_{i}.jpg\"\n",
    "            f_path = os.path.join(\"output_dir\", frame_name)\n",
    "            cv2.imwrite(f_path,frame)\n",
    "            k+=1\n",
    "            i+=1\n",
    "            ret,frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "        if(k>0):\n",
    "            k=0\n",
    "            while(k<25):\n",
    "                i+=1\n",
    "                k+=1\n",
    "                ret,frame=cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "    i+=1\n",
    "print('Saved')\n",
    "print('total time: ',time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes:  [[758, 280, 54, 196], [761, 280, 59, 196], [574, 366, 84, 203], [568, 363, 99, 209], [577, 368, 83, 210], [570, 368, 98, 209]]\n",
      "172.0   95.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('./op/frame_436.jpg')\n",
    "val,coord=isInteresting(image)\n",
    "print(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
