{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9374\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytube\n",
    "import time\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "# Load YOLO object detection model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load COCO class labels\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Set minimum confidence level for object detection\n",
    "conf_threshold = 0.5\n",
    "\n",
    "# Set non-maximum suppression threshold to suppress overlapping detections\n",
    "nms_threshold = 0.4\n",
    "\n",
    "# Load video from URL\n",
    "url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "video = pytube.YouTube(url)\n",
    "stream = video.streams.get_by_itag(22)\n",
    "file = stream.download()    \n",
    "cap = cv2.VideoCapture(file)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_duration=total_frames/frame_rate\n",
    "\n",
    "# Initialize variables\n",
    "timestamps = []\n",
    "frame_count = 0\n",
    "frame_c=0\n",
    "print(total_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame no: 1\n",
      "frame no: 2\n",
      "frame no: 3\n",
      "frame no: 4\n",
      "frame no: 5\n",
      "frame no: 6\n",
      "frame no: 7\n",
      "frame no: 8\n",
      "frame no: 9\n",
      "frame no: 10\n",
      "frame no: 11\n",
      "frame no: 12\n",
      "frame no: 13\n",
      "frame no: 14\n",
      "frame no: 15\n",
      "frame no: 16\n",
      "frame no: 17\n",
      "frame no: 18\n",
      "frame no: 19\n",
      "frame no: 20\n",
      "frame no: 21\n",
      "frame no: 22\n",
      "frame no: 23\n",
      "frame no: 24\n",
      "frame no: 25\n",
      "frame no: 26\n",
      "frame no: 27\n",
      "frame no: 28\n",
      "frame no: 29\n",
      "frame no: 30\n",
      "frame no: 31\n",
      "frame no: 32\n",
      "frame no: 33\n",
      "frame no: 34\n",
      "frame no: 35\n",
      "frame no: 36\n",
      "frame no: 37\n",
      "frame no: 38\n",
      "frame no: 39\n",
      "frame no: 40\n",
      "frame no: 41\n",
      "frame no: 42\n",
      "frame no: 43\n",
      "frame no: 44\n",
      "frame no: 45\n",
      "frame no: 46\n",
      "frame no: 47\n",
      "frame no: 48\n",
      "frame no: 49\n",
      "frame no: 50\n",
      "frame no: 51\n",
      "frame no: 52\n",
      "frame no: 53\n",
      "frame no: 54\n",
      "frame no: 55\n",
      "frame no: 56\n",
      "frame no: 57\n",
      "frame no: 58\n",
      "frame no: 59\n",
      "frame no: 60\n",
      "frame no: 61\n",
      "frame no: 62\n",
      "frame no: 63\n",
      "frame no: 64\n",
      "frame no: 65\n",
      "frame no: 66\n",
      "frame no: 67\n",
      "frame no: 68\n",
      "frame no: 69\n",
      "frame no: 70\n",
      "frame no: 71\n",
      "frame no: 72\n",
      "frame no: 73\n",
      "frame no: 74\n",
      "frame no: 75\n",
      "frame no: 76\n",
      "frame no: 77\n",
      "frame no: 78\n",
      "frame no: 79\n",
      "frame no: 80\n",
      "frame no: 81\n",
      "frame no: 82\n",
      "frame no: 83\n",
      "frame no: 84\n",
      "frame no: 85\n",
      "frame no: 86\n",
      "frame no: 87\n",
      "frame no: 88\n",
      "frame no: 89\n",
      "frame no: 90\n",
      "frame no: 91\n",
      "frame no: 92\n",
      "frame no: 93\n",
      "frame no: 94\n",
      "frame no: 95\n",
      "frame no: 96\n",
      "frame no: 97\n",
      "frame no: 98\n",
      "frame no: 99\n",
      "frame no: 100\n",
      "frame no: 101\n",
      "frame no: 102\n",
      "frame no: 103\n",
      "frame no: 104\n",
      "frame no: 105\n",
      "frame no: 106\n",
      "frame no: 107\n",
      "frame no: 108\n",
      "frame no: 109\n",
      "frame no: 110\n",
      "frame no: 111\n",
      "frame no: 112\n",
      "frame no: 113\n",
      "frame no: 114\n",
      "frame no: 115\n",
      "frame no: 116\n",
      "frame no: 117\n",
      "frame no: 118\n",
      "frame no: 119\n",
      "frame no: 120\n",
      "frame no: 121\n",
      "frame no: 122\n",
      "frame no: 123\n",
      "frame no: 124\n",
      "frame no: 125\n",
      "frame no: 126\n",
      "frame no: 127\n",
      "frame no: 128\n",
      "frame no: 129\n",
      "frame no: 130\n",
      "frame no: 131\n",
      "frame no: 132\n",
      "frame no: 133\n",
      "frame no: 134\n",
      "frame no: 135\n",
      "frame no: 136\n",
      "frame no: 137\n",
      "frame no: 138\n",
      "frame no: 139\n",
      "frame no: 140\n",
      "frame no: 141\n",
      "frame no: 142\n",
      "frame no: 143\n",
      "frame no: 144\n",
      "frame no: 145\n",
      "frame no: 146\n",
      "frame no: 147\n",
      "frame no: 148\n",
      "frame no: 149\n",
      "frame no: 150\n",
      "frame no: 151\n",
      "frame no: 152\n",
      "frame no: 153\n",
      "frame no: 154\n",
      "frame no: 155\n",
      "frame no: 156\n",
      "frame no: 157\n",
      "frame no: 158\n",
      "frame no: 159\n",
      "frame no: 160\n",
      "frame no: 161\n",
      "frame no: 162\n",
      "frame no: 163\n",
      "frame no: 164\n",
      "frame no: 165\n",
      "frame no: 166\n",
      "frame no: 167\n",
      "frame no: 168\n",
      "frame no: 169\n",
      "frame no: 170\n",
      "frame no: 171\n",
      "frame no: 172\n",
      "frame no: 173\n",
      "frame no: 174\n",
      "frame no: 175\n",
      "frame no: 176\n",
      "frame no: 177\n",
      "frame no: 178\n",
      "frame no: 179\n",
      "frame no: 180\n",
      "frame no: 181\n",
      "frame no: 182\n",
      "frame no: 183\n",
      "frame no: 184\n",
      "frame no: 185\n",
      "frame no: 186\n",
      "frame no: 187\n",
      "frame no: 188\n",
      "frame no: 189\n",
      "frame no: 190\n",
      "frame no: 191\n",
      "frame no: 192\n",
      "frame no: 193\n",
      "frame no: 194\n",
      "frame no: 195\n",
      "frame no: 196\n",
      "frame no: 197\n",
      "frame no: 198\n",
      "frame no: 199\n",
      "frame no: 200\n",
      "frame no: 201\n",
      "frame no: 202\n",
      "frame no: 203\n",
      "frame no: 204\n",
      "frame no: 205\n",
      "frame no: 206\n",
      "frame no: 207\n",
      "frame no: 208\n",
      "frame no: 209\n",
      "frame no: 210\n",
      "frame no: 211\n",
      "frame no: 212\n",
      "frame no: 213\n",
      "frame no: 214\n",
      "frame no: 215\n",
      "frame no: 216\n",
      "frame no: 217\n",
      "frame no: 218\n",
      "frame no: 219\n",
      "frame no: 220\n",
      "frame no: 221\n",
      "frame no: 222\n",
      "frame no: 223\n",
      "frame no: 224\n",
      "frame no: 225\n",
      "frame no: 226\n",
      "frame no: 227\n",
      "frame no: 228\n",
      "frame no: 229\n",
      "frame no: 230\n",
      "frame no: 231\n",
      "frame no: 232\n",
      "frame no: 233\n",
      "frame no: 234\n",
      "frame no: 235\n",
      "frame no: 236\n",
      "frame no: 237\n",
      "frame no: 238\n",
      "frame no: 239\n",
      "frame no: 240\n",
      "frame no: 241\n",
      "frame no: 242\n",
      "frame no: 243\n",
      "frame no: 244\n",
      "frame no: 245\n",
      "frame no: 246\n",
      "frame no: 247\n",
      "frame no: 248\n",
      "frame no: 249\n",
      "frame no: 250\n",
      "frame no: 251\n",
      "frame no: 252\n",
      "frame no: 253\n",
      "frame no: 254\n",
      "frame no: 255\n",
      "frame no: 256\n",
      "frame no: 257\n",
      "frame no: 258\n",
      "frame no: 259\n",
      "frame no: 260\n",
      "frame no: 261\n",
      "frame no: 262\n",
      "frame no: 263\n",
      "frame no: 264\n",
      "frame no: 265\n",
      "frame no: 266\n",
      "frame no: 267\n",
      "frame no: 268\n",
      "frame no: 269\n",
      "frame no: 270\n",
      "frame no: 271\n",
      "frame no: 272\n",
      "frame no: 273\n",
      "frame no: 274\n",
      "frame no: 275\n",
      "frame no: 276\n",
      "frame no: 277\n",
      "frame no: 278\n",
      "frame no: 279\n",
      "frame no: 280\n",
      "frame no: 281\n",
      "frame no: 282\n",
      "frame no: 283\n",
      "frame no: 284\n",
      "frame no: 285\n",
      "frame no: 286\n",
      "frame no: 287\n",
      "frame no: 288\n",
      "frame no: 289\n",
      "frame no: 290\n",
      "frame no: 291\n",
      "frame no: 292\n",
      "frame no: 293\n",
      "frame no: 294\n",
      "frame no: 295\n",
      "frame no: 296\n",
      "frame no: 297\n",
      "frame no: 298\n",
      "frame no: 299\n",
      "frame no: 300\n",
      "frame no: 301\n",
      "frame no: 302\n",
      "frame no: 303\n",
      "frame no: 304\n",
      "frame no: 305\n",
      "frame no: 306\n",
      "frame no: 307\n",
      "frame no: 308\n",
      "frame no: 309\n",
      "frame no: 310\n",
      "frame no: 311\n",
      "frame no: 312\n",
      "frame no: 313\n",
      "frame no: 314\n",
      "frame no: 315\n",
      "frame no: 316\n",
      "frame no: 317\n",
      "frame no: 318\n",
      "frame no: 319\n",
      "frame no: 320\n",
      "frame no: 321\n",
      "frame no: 322\n",
      "frame no: 323\n",
      "frame no: 324\n",
      "frame no: 325\n",
      "frame no: 326\n",
      "frame no: 327\n",
      "frame no: 328\n",
      "frame no: 329\n",
      "frame no: 330\n",
      "frame no: 331\n",
      "frame no: 332\n",
      "frame no: 333\n",
      "frame no: 334\n",
      "frame no: 335\n",
      "frame no: 336\n",
      "frame no: 337\n",
      "frame no: 338\n",
      "frame no: 339\n",
      "frame no: 340\n",
      "frame no: 341\n",
      "frame no: 342\n",
      "frame no: 343\n",
      "frame no: 344\n",
      "frame no: 345\n",
      "frame no: 346\n",
      "frame no: 347\n",
      "frame no: 348\n",
      "frame no: 349\n",
      "frame no: 350\n",
      "frame no: 351\n",
      "frame no: 352\n",
      "frame no: 353\n",
      "frame no: 354\n",
      "frame no: 355\n",
      "frame no: 356\n",
      "frame no: 357\n",
      "frame no: 358\n",
      "frame no: 359\n",
      "frame no: 360\n",
      "frame no: 361\n",
      "frame no: 362\n",
      "frame no: 363\n",
      "frame no: 364\n",
      "frame no: 365\n",
      "frame no: 366\n",
      "frame no: 367\n",
      "frame no: 368\n",
      "frame no: 369\n",
      "frame no: 370\n",
      "frame no: 371\n",
      "frame no: 372\n",
      "frame no: 373\n",
      "frame no: 374\n",
      "frame no: 375\n",
      "frame no: 376\n",
      "frame no: 377\n",
      "frame no: 378\n",
      "frame no: 379\n",
      "frame no: 380\n",
      "frame no: 381\n",
      "frame no: 382\n",
      "frame no: 383\n",
      "frame no: 384\n",
      "frame no: 385\n",
      "frame no: 386\n",
      "frame no: 387\n",
      "frame no: 388\n",
      "frame no: 389\n",
      "frame no: 390\n",
      "frame no: 391\n",
      "frame no: 392\n",
      "frame no: 393\n",
      "frame no: 394\n",
      "frame no: 395\n",
      "frame no: 396\n",
      "frame no: 397\n",
      "frame no: 398\n",
      "frame no: 399\n",
      "frame no: 400\n",
      "frame no: 401\n",
      "frame no: 402\n",
      "frame no: 403\n",
      "frame no: 404\n",
      "frame no: 405\n",
      "frame no: 406\n",
      "frame no: 407\n",
      "frame no: 408\n",
      "frame no: 409\n",
      "frame no: 410\n",
      "frame no: 411\n",
      "frame no: 412\n",
      "frame no: 413\n",
      "frame no: 414\n",
      "frame no: 415\n",
      "frame no: 416\n",
      "frame no: 417\n",
      "frame no: 418\n",
      "frame no: 419\n",
      "frame no: 420\n",
      "frame no: 421\n",
      "frame no: 422\n",
      "frame no: 423\n",
      "frame no: 424\n",
      "frame no: 425\n",
      "frame no: 426\n",
      "frame no: 427\n",
      "frame no: 428\n",
      "frame no: 429\n",
      "frame no: 430\n",
      "frame no: 431\n",
      "frame no: 432\n",
      "frame no: 433\n",
      "frame no: 434\n",
      "frame no: 435\n",
      "frame no: 436\n",
      "frame no: 437\n",
      "frame no: 438\n",
      "frame no: 439\n",
      "frame no: 440\n",
      "frame no: 441\n",
      "frame no: 442\n",
      "frame no: 443\n",
      "frame no: 444\n",
      "frame no: 445\n",
      "frame no: 446\n",
      "frame no: 447\n",
      "frame no: 448\n",
      "frame no: 449\n",
      "frame no: 450\n",
      "frame no: 451\n",
      "frame no: 452\n",
      "frame no: 453\n",
      "frame no: 454\n",
      "frame no: 455\n",
      "frame no: 456\n",
      "frame no: 457\n",
      "frame no: 458\n",
      "frame no: 459\n",
      "frame no: 460\n",
      "frame no: 461\n",
      "frame no: 462\n",
      "frame no: 463\n",
      "frame no: 464\n",
      "frame no: 465\n",
      "frame no: 466\n",
      "frame no: 467\n",
      "frame no: 468\n",
      "frame no: 469\n",
      "frame no: 470\n",
      "frame no: 471\n",
      "frame no: 472\n",
      "frame no: 473\n",
      "frame no: 474\n",
      "frame no: 475\n",
      "frame no: 476\n",
      "frame no: 477\n",
      "frame no: 478\n",
      "frame no: 479\n",
      "frame no: 480\n",
      "frame no: 481\n",
      "frame no: 482\n",
      "frame no: 483\n",
      "frame no: 484\n",
      "frame no: 485\n",
      "frame no: 486\n",
      "frame no: 487\n",
      "frame no: 488\n",
      "frame no: 489\n",
      "frame no: 490\n",
      "frame no: 491\n",
      "frame no: 492\n",
      "frame no: 493\n",
      "frame no: 494\n",
      "frame no: 495\n",
      "frame no: 496\n",
      "frame no: 497\n",
      "frame no: 498\n",
      "frame no: 499\n",
      "frame no: 500\n",
      "frame no: 501\n",
      "frame no: 502\n",
      "frame no: 503\n",
      "frame no: 504\n",
      "frame no: 505\n",
      "frame no: 506\n",
      "frame no: 507\n",
      "frame no: 508\n",
      "frame no: 509\n",
      "frame no: 510\n",
      "frame no: 511\n",
      "frame no: 512\n",
      "frame no: 513\n",
      "frame no: 514\n",
      "frame no: 515\n",
      "frame no: 516\n",
      "frame no: 517\n",
      "frame no: 518\n",
      "frame no: 519\n",
      "frame no: 520\n",
      "frame no: 521\n",
      "frame no: 522\n",
      "frame no: 523\n",
      "frame no: 524\n",
      "frame no: 525\n",
      "frame no: 526\n",
      "frame no: 527\n",
      "frame no: 528\n",
      "frame no: 529\n",
      "frame no: 530\n",
      "frame no: 531\n",
      "frame no: 532\n",
      "frame no: 533\n",
      "frame no: 534\n",
      "frame no: 535\n",
      "frame no: 536\n",
      "frame no: 537\n",
      "frame no: 538\n",
      "frame no: 539\n",
      "frame no: 540\n",
      "frame no: 541\n",
      "frame no: 542\n",
      "frame no: 543\n",
      "frame no: 544\n",
      "frame no: 545\n",
      "frame no: 546\n",
      "frame no: 547\n",
      "frame no: 548\n",
      "frame no: 549\n",
      "frame no: 550\n",
      "frame no: 551\n",
      "frame no: 552\n",
      "frame no: 553\n",
      "frame no: 554\n",
      "frame no: 555\n",
      "frame no: 556\n",
      "frame no: 557\n",
      "frame no: 558\n",
      "frame no: 559\n",
      "frame no: 560\n",
      "frame no: 561\n",
      "frame no: 562\n",
      "frame no: 563\n",
      "frame no: 564\n",
      "frame no: 565\n",
      "frame no: 566\n",
      "frame no: 567\n",
      "frame no: 568\n",
      "frame no: 569\n",
      "frame no: 570\n",
      "frame no: 571\n",
      "frame no: 572\n",
      "frame no: 573\n",
      "frame no: 574\n",
      "frame no: 575\n",
      "frame no: 576\n",
      "frame no: 577\n",
      "frame no: 578\n",
      "frame no: 579\n",
      "frame no: 580\n",
      "frame no: 581\n",
      "frame no: 582\n",
      "frame no: 583\n",
      "frame no: 584\n",
      "frame no: 585\n",
      "frame no: 586\n",
      "frame no: 587\n",
      "frame no: 588\n",
      "frame no: 589\n",
      "frame no: 590\n",
      "frame no: 591\n",
      "frame no: 592\n",
      "frame no: 593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame no: 594\n",
      "frame no: 595\n",
      "frame no: 596\n",
      "frame no: 597\n",
      "frame no: 598\n",
      "frame no: 599\n",
      "frame no: 600\n",
      "frame no: 601\n",
      "frame no: 602\n",
      "frame no: 603\n",
      "frame no: 604\n",
      "frame no: 605\n",
      "frame no: 606\n",
      "frame no: 607\n",
      "frame no: 608\n",
      "frame no: 609\n",
      "frame no: 610\n",
      "frame no: 611\n",
      "frame no: 612\n",
      "frame no: 613\n",
      "frame no: 614\n",
      "frame no: 615\n",
      "frame no: 616\n",
      "frame no: 617\n",
      "frame no: 618\n",
      "frame no: 619\n",
      "frame no: 620\n",
      "frame no: 621\n",
      "frame no: 622\n",
      "frame no: 623\n",
      "frame no: 624\n",
      "frame no: 625\n",
      "frame no: 626\n",
      "frame no: 627\n",
      "frame no: 628\n",
      "frame no: 629\n",
      "frame no: 630\n",
      "frame no: 631\n",
      "frame no: 632\n",
      "frame no: 633\n",
      "frame no: 634\n",
      "frame no: 635\n",
      "frame no: 636\n",
      "frame no: 637\n",
      "frame no: 638\n",
      "frame no: 639\n",
      "frame no: 640\n",
      "frame no: 641\n",
      "frame no: 642\n",
      "frame no: 643\n",
      "frame no: 644\n",
      "frame no: 645\n",
      "frame no: 646\n",
      "frame no: 647\n",
      "frame no: 648\n",
      "frame no: 649\n",
      "frame no: 650\n",
      "frame no: 651\n",
      "frame no: 652\n",
      "frame no: 653\n",
      "frame no: 654\n",
      "frame no: 655\n",
      "frame no: 656\n",
      "frame no: 657\n",
      "frame no: 658\n",
      "frame no: 659\n",
      "frame no: 660\n",
      "frame no: 661\n",
      "frame no: 662\n",
      "frame no: 663\n",
      "frame no: 664\n",
      "frame no: 665\n",
      "frame no: 666\n",
      "frame no: 667\n",
      "frame no: 668\n",
      "frame no: 669\n",
      "frame no: 670\n",
      "frame no: 671\n",
      "frame no: 672\n",
      "frame no: 673\n",
      "frame no: 674\n",
      "frame no: 675\n",
      "frame no: 676\n",
      "frame no: 677\n",
      "frame no: 678\n",
      "frame no: 679\n",
      "frame no: 680\n",
      "frame no: 681\n",
      "frame no: 682\n",
      "frame no: 683\n",
      "frame no: 684\n",
      "frame no: 685\n",
      "frame no: 686\n",
      "frame no: 687\n",
      "frame no: 688\n",
      "frame no: 689\n",
      "frame no: 690\n",
      "frame no: 691\n",
      "frame no: 692\n",
      "frame no: 693\n",
      "frame no: 694\n",
      "frame no: 695\n",
      "frame no: 696\n",
      "frame no: 697\n",
      "frame no: 698\n",
      "frame no: 699\n",
      "frame no: 700\n",
      "frame no: 701\n",
      "frame no: 702\n",
      "frame no: 703\n",
      "frame no: 704\n",
      "frame no: 705\n",
      "frame no: 706\n",
      "frame no: 707\n",
      "frame no: 708\n",
      "frame no: 709\n",
      "frame no: 710\n",
      "frame no: 711\n",
      "frame no: 712\n",
      "frame no: 713\n",
      "frame no: 714\n",
      "frame no: 715\n",
      "frame no: 716\n",
      "frame no: 717\n",
      "frame no: 718\n",
      "frame no: 719\n",
      "frame no: 720\n",
      "frame no: 721\n",
      "frame no: 722\n",
      "frame no: 723\n",
      "frame no: 724\n",
      "frame no: 725\n",
      "frame no: 726\n",
      "frame no: 727\n",
      "frame no: 728\n",
      "frame no: 729\n",
      "frame no: 730\n",
      "frame no: 731\n",
      "frame no: 732\n",
      "frame no: 733\n",
      "frame no: 734\n",
      "frame no: 735\n",
      "frame no: 736\n",
      "frame no: 737\n",
      "frame no: 738\n",
      "frame no: 739\n",
      "frame no: 740\n",
      "frame no: 741\n",
      "frame no: 742\n",
      "frame no: 743\n",
      "frame no: 744\n",
      "frame no: 745\n",
      "frame no: 746\n",
      "frame no: 747\n",
      "frame no: 748\n",
      "frame no: 749\n",
      "frame no: 750\n",
      "frame no: 751\n",
      "frame no: 752\n",
      "frame no: 753\n",
      "frame no: 754\n",
      "frame no: 755\n",
      "frame no: 756\n",
      "frame no: 757\n",
      "frame no: 758\n",
      "frame no: 759\n",
      "frame no: 760\n",
      "frame no: 761\n",
      "frame no: 762\n",
      "frame no: 763\n",
      "frame no: 764\n",
      "frame no: 765\n",
      "frame no: 766\n",
      "frame no: 767\n",
      "frame no: 768\n",
      "frame no: 769\n",
      "frame no: 770\n",
      "frame no: 771\n",
      "frame no: 772\n",
      "frame no: 773\n",
      "frame no: 774\n",
      "frame no: 775\n",
      "frame no: 776\n",
      "frame no: 777\n",
      "frame no: 778\n",
      "frame no: 779\n",
      "frame no: 780\n",
      "frame no: 781\n",
      "frame no: 782\n",
      "frame no: 783\n",
      "frame no: 784\n",
      "frame no: 785\n",
      "frame no: 786\n",
      "frame no: 787\n",
      "frame no: 788\n",
      "frame no: 789\n",
      "frame no: 790\n",
      "frame no: 791\n",
      "frame no: 792\n",
      "frame no: 793\n",
      "frame no: 794\n",
      "frame no: 795\n",
      "frame no: 796\n",
      "frame no: 797\n",
      "frame no: 798\n",
      "frame no: 799\n",
      "frame no: 800\n",
      "frame no: 801\n",
      "frame no: 802\n",
      "frame no: 803\n",
      "frame no: 804\n",
      "frame no: 805\n",
      "frame no: 806\n",
      "frame no: 807\n",
      "frame no: 808\n",
      "frame no: 809\n",
      "frame no: 810\n",
      "frame no: 811\n",
      "frame no: 812\n",
      "frame no: 813\n",
      "frame no: 814\n",
      "frame no: 815\n",
      "frame no: 816\n",
      "frame no: 817\n",
      "frame no: 818\n",
      "frame no: 819\n",
      "frame no: 820\n",
      "frame no: 821\n",
      "frame no: 822\n",
      "frame no: 823\n",
      "frame no: 824\n",
      "frame no: 825\n",
      "frame no: 826\n",
      "frame no: 827\n",
      "frame no: 828\n",
      "frame no: 829\n",
      "frame no: 830\n",
      "frame no: 831\n",
      "frame no: 832\n",
      "frame no: 833\n",
      "frame no: 834\n",
      "frame no: 835\n",
      "frame no: 836\n",
      "frame no: 837\n",
      "frame no: 838\n",
      "frame no: 839\n",
      "frame no: 840\n",
      "frame no: 841\n",
      "frame no: 842\n",
      "frame no: 843\n",
      "frame no: 844\n",
      "frame no: 845\n",
      "frame no: 846\n",
      "frame no: 847\n",
      "frame no: 848\n",
      "frame no: 849\n",
      "frame no: 850\n",
      "frame no: 851\n",
      "frame no: 852\n",
      "frame no: 853\n",
      "frame no: 854\n",
      "frame no: 855\n",
      "frame no: 856\n",
      "frame no: 857\n",
      "frame no: 858\n",
      "frame no: 859\n",
      "frame no: 860\n",
      "frame no: 861\n",
      "frame no: 862\n",
      "frame no: 863\n",
      "frame no: 864\n",
      "frame no: 865\n",
      "frame no: 866\n",
      "frame no: 867\n",
      "frame no: 868\n",
      "frame no: 869\n",
      "frame no: 870\n",
      "frame no: 871\n",
      "frame no: 872\n",
      "frame no: 873\n",
      "frame no: 874\n",
      "frame no: 875\n",
      "frame no: 876\n",
      "frame no: 877\n",
      "frame no: 878\n",
      "frame no: 879\n",
      "frame no: 880\n",
      "frame no: 881\n",
      "frame no: 882\n",
      "frame no: 883\n",
      "frame no: 884\n",
      "frame no: 885\n",
      "frame no: 886\n",
      "frame no: 887\n",
      "frame no: 888\n",
      "frame no: 889\n",
      "frame no: 890\n",
      "frame no: 891\n",
      "frame no: 892\n",
      "frame no: 893\n",
      "frame no: 894\n",
      "frame no: 895\n",
      "frame no: 896\n",
      "frame no: 897\n",
      "frame no: 898\n",
      "frame no: 899\n",
      "frame no: 900\n",
      "frame no: 901\n",
      "frame no: 902\n",
      "frame no: 903\n",
      "frame no: 904\n",
      "frame no: 905\n",
      "frame no: 906\n",
      "frame no: 907\n",
      "frame no: 908\n",
      "frame no: 909\n",
      "frame no: 910\n",
      "frame no: 911\n",
      "frame no: 912\n",
      "frame no: 913\n",
      "frame no: 914\n",
      "frame no: 915\n",
      "frame no: 916\n",
      "frame no: 917\n",
      "frame no: 918\n",
      "frame no: 919\n",
      "frame no: 920\n",
      "frame no: 921\n",
      "frame no: 922\n",
      "frame no: 923\n",
      "frame no: 924\n",
      "frame no: 925\n",
      "frame no: 926\n",
      "frame no: 927\n",
      "frame no: 928\n",
      "frame no: 929\n",
      "frame no: 930\n",
      "frame no: 931\n",
      "frame no: 932\n",
      "frame no: 933\n",
      "frame no: 934\n",
      "frame no: 935\n",
      "frame no: 936\n",
      "frame no: 937\n",
      "frame no: 938\n",
      "frame no: 939\n",
      "frame no: 940\n",
      "frame no: 941\n",
      "frame no: 942\n",
      "frame no: 943\n",
      "frame no: 944\n",
      "frame no: 945\n",
      "frame no: 946\n",
      "frame no: 947\n",
      "frame no: 948\n",
      "frame no: 949\n",
      "frame no: 950\n",
      "frame no: 951\n",
      "frame no: 952\n",
      "frame no: 953\n",
      "frame no: 954\n",
      "frame no: 955\n",
      "frame no: 956\n",
      "frame no: 957\n",
      "frame no: 958\n",
      "frame no: 959\n",
      "frame no: 960\n",
      "frame no: 961\n",
      "frame no: 962\n",
      "frame no: 963\n",
      "frame no: 964\n",
      "frame no: 965\n",
      "frame no: 966\n",
      "frame no: 967\n",
      "frame no: 968\n",
      "frame no: 969\n",
      "frame no: 970\n",
      "frame no: 971\n",
      "frame no: 972\n",
      "frame no: 973\n",
      "frame no: 974\n",
      "frame no: 975\n",
      "frame no: 976\n",
      "frame no: 977\n",
      "frame no: 978\n",
      "frame no: 979\n",
      "frame no: 980\n",
      "frame no: 981\n",
      "frame no: 982\n",
      "frame no: 983\n",
      "frame no: 984\n",
      "frame no: 985\n",
      "frame no: 986\n",
      "frame no: 987\n",
      "frame no: 988\n",
      "frame no: 989\n",
      "frame no: 990\n",
      "frame no: 991\n",
      "frame no: 992\n",
      "frame no: 993\n",
      "frame no: 994\n",
      "frame no: 995\n",
      "frame no: 996\n",
      "frame no: 997\n",
      "frame no: 998\n",
      "frame no: 999\n",
      "frame no: 1000\n",
      "total time 635.123378276825\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Read frame from video\n",
    "    ret, frame = cap.read()\n",
    "    if frame_c == 1000:\n",
    "        break;\n",
    "    frame_c+=1\n",
    "    print(\"frame no:\",frame_c)\n",
    "    if ret:\n",
    "        # Get dimensions of frame\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        # Create input blob for YOLO model\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "        # Set input blob for YOLO model\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get output layer names of YOLO model\n",
    "        output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "        # Forward pass through YOLO model to get object detection results\n",
    "        layer_outputs = net.forward(output_layer_names)\n",
    "\n",
    "        # Initialize lists to store object detection results\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Process each output layer\n",
    "        for output in layer_outputs:\n",
    "            # Process each detection in output\n",
    "            for detection in output:\n",
    "                # Extract class probabilities, box coordinates and objectness confidence\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > conf_threshold:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply non-maximum suppression to remove overlapping detections\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        # Draw bounding boxes around detected objects and output class names and confidence scores\n",
    "        for i in indices:\n",
    "            box = boxes[i]\n",
    "            x = box[0]\n",
    "            y = box[1]\n",
    "            w = box[2]\n",
    "            h = box[3]\n",
    "            label = classes[class_ids[i]]\n",
    "            confidence = confidences[i]\n",
    "            if label == 'baseball bat' :\n",
    "                # Store timestamp of frame when bat is detected\n",
    "                timestamps.append(int(cap.get(cv2.CAP_PROP_POS_MSEC) / 1000))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} {confidence}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"total time\",time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{33, 2, 34, 18, 24, 25}\n"
     ]
    }
   ],
   "source": [
    "print(timestamps)\n",
    "timestamps=set(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video file: https://www.youtube.com/watch?v=AFEZzf9_EHk\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def save_frames_from_video(video_url, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Open the video file\n",
    "    video = pytube.YouTube(url)\n",
    "    stream = video.streams.get_by_itag(22)\n",
    "    file = stream.download()    \n",
    "    video_capture = cv2.VideoCapture(file)\n",
    "    \n",
    "    # Check if the video file is opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error opening video file:\", video_url)\n",
    "        return\n",
    "    \n",
    "    # Read and save each frame until the end of the video\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        # Check if frame was successfully read\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save the frame as an image file\n",
    "        frame_filename = f\"frame_{frame_count:04d}.jpg\"\n",
    "        frame_path = os.path.join(output_folder, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        # Increment frame count\n",
    "        frame_count += 1\n",
    "    \n",
    "    # Release the video file and print summary\n",
    "    video_capture.release()\n",
    "    print(\"Frames saved:\", frame_count)\n",
    "\n",
    "# Example usage\n",
    "video_url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"  \n",
    "output_folder = \"frames\"  \n",
    "\n",
    "save_frames_from_video(video_url, \"output_dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9374\n",
      "count:  10\n",
      "count:  20\n",
      "count:  30\n",
      "count:  40\n",
      "count:  50\n",
      "count:  60\n",
      "count:  70\n",
      "count:  80\n",
      "count:  90\n",
      "count:  100\n",
      "count:  110\n",
      "count:  120\n",
      "count:  130\n",
      "count:  140\n",
      "count:  150\n",
      "count:  160\n",
      "count:  170\n",
      "count:  180\n",
      "count:  190\n",
      "count:  200\n",
      "count:  210\n",
      "count:  220\n",
      "count:  230\n",
      "count:  240\n",
      "count:  250\n",
      "count:  260\n",
      "count:  270\n",
      "count:  280\n",
      "count:  290\n",
      "count:  300\n",
      "count:  310\n",
      "count:  320\n",
      "count:  330\n",
      "count:  340\n",
      "count:  350\n",
      "count:  360\n",
      "count:  370\n",
      "count:  380\n",
      "count:  390\n",
      "count:  400\n",
      "count:  410\n",
      "count:  420\n",
      "count:  430\n",
      "count:  440\n",
      "count:  450\n",
      "count:  460\n",
      "count:  470\n",
      "count:  480\n",
      "count:  490\n",
      "count:  500\n",
      "count:  510\n",
      "count:  520\n",
      "count:  530\n",
      "count:  540\n",
      "count:  550\n",
      "count:  560\n",
      "count:  570\n",
      "count:  580\n",
      "count:  590\n",
      "count:  600\n",
      "count:  610\n",
      "count:  620\n",
      "count:  630\n",
      "count:  640\n",
      "count:  650\n",
      "count:  660\n",
      "count:  670\n",
      "count:  680\n",
      "count:  690\n",
      "count:  700\n",
      "count:  710\n",
      "count:  720\n",
      "count:  730\n",
      "count:  740\n",
      "count:  750\n",
      "count:  760\n",
      "count:  770\n",
      "count:  780\n",
      "count:  790\n",
      "count:  800\n",
      "count:  810\n",
      "count:  820\n",
      "count:  830\n",
      "count:  840\n",
      "count:  850\n",
      "count:  860\n",
      "count:  870\n",
      "count:  880\n",
      "count:  890\n",
      "count:  900\n",
      "count:  910\n",
      "count:  920\n",
      "count:  930\n",
      "count:  940\n",
      "count:  950\n",
      "count:  960\n",
      "count:  970\n",
      "count:  980\n",
      "count:  990\n",
      "count:  1000\n",
      "count:  1010\n",
      "count:  1020\n",
      "count:  1030\n",
      "count:  1040\n",
      "count:  1050\n",
      "count:  1060\n",
      "count:  1070\n",
      "count:  1080\n",
      "count:  1090\n",
      "count:  1100\n",
      "count:  1110\n",
      "count:  1120\n",
      "count:  1130\n",
      "count:  1140\n",
      "count:  1150\n",
      "count:  1160\n",
      "count:  1170\n",
      "count:  1180\n",
      "count:  1190\n",
      "count:  1200\n",
      "count:  1210\n",
      "count:  1220\n",
      "count:  1230\n",
      "count:  1240\n",
      "count:  1250\n",
      "count:  1260\n",
      "count:  1270\n",
      "count:  1280\n",
      "count:  1290\n",
      "count:  1300\n",
      "count:  1310\n",
      "count:  1320\n",
      "count:  1330\n",
      "count:  1340\n",
      "count:  1350\n",
      "count:  1360\n",
      "count:  1370\n",
      "count:  1380\n",
      "count:  1390\n",
      "count:  1400\n",
      "count:  1410\n",
      "count:  1420\n",
      "count:  1430\n",
      "count:  1440\n",
      "count:  1450\n",
      "count:  1460\n",
      "count:  1470\n",
      "count:  1480\n",
      "count:  1490\n",
      "count:  1500\n",
      "count:  1510\n",
      "count:  1520\n",
      "count:  1530\n",
      "count:  1540\n",
      "count:  1550\n",
      "count:  1560\n",
      "count:  1570\n",
      "count:  1580\n",
      "count:  1590\n",
      "count:  1600\n",
      "count:  1610\n",
      "count:  1620\n",
      "count:  1630\n",
      "count:  1640\n",
      "count:  1650\n",
      "count:  1660\n",
      "count:  1670\n",
      "count:  1680\n",
      "count:  1690\n",
      "count:  1700\n",
      "count:  1710\n",
      "count:  1720\n",
      "count:  1730\n",
      "count:  1740\n",
      "count:  1750\n",
      "count:  1760\n",
      "count:  1770\n",
      "count:  1780\n",
      "count:  1790\n",
      "count:  1800\n",
      "count:  1810\n",
      "count:  1820\n",
      "count:  1830\n",
      "count:  1840\n",
      "count:  1850\n",
      "count:  1860\n",
      "count:  1870\n",
      "count:  1880\n",
      "count:  1890\n",
      "count:  1900\n",
      "count:  1910\n",
      "count:  1920\n",
      "count:  1930\n",
      "count:  1940\n",
      "count:  1950\n",
      "count:  1960\n",
      "count:  1970\n",
      "count:  1980\n",
      "count:  1990\n",
      "count:  2000\n",
      "count:  2010\n",
      "count:  2020\n",
      "count:  2030\n",
      "count:  2040\n",
      "count:  2050\n",
      "count:  2060\n",
      "count:  2070\n",
      "count:  2080\n",
      "count:  2090\n",
      "count:  2100\n",
      "count:  2110\n",
      "count:  2120\n",
      "count:  2130\n",
      "count:  2140\n",
      "count:  2150\n",
      "count:  2160\n",
      "count:  2170\n",
      "count:  2180\n",
      "count:  2190\n",
      "count:  2200\n",
      "count:  2210\n",
      "count:  2220\n",
      "count:  2230\n",
      "count:  2240\n",
      "count:  2250\n",
      "count:  2260\n",
      "count:  2270\n",
      "count:  2280\n",
      "count:  2290\n",
      "count:  2300\n",
      "count:  2310\n",
      "count:  2320\n",
      "count:  2330\n",
      "count:  2340\n",
      "count:  2350\n",
      "count:  2360\n",
      "count:  2370\n",
      "count:  2380\n",
      "count:  2390\n",
      "count:  2400\n",
      "count:  2410\n",
      "count:  2420\n",
      "count:  2430\n",
      "count:  2440\n",
      "count:  2450\n",
      "count:  2460\n",
      "count:  2470\n",
      "count:  2480\n",
      "count:  2490\n",
      "count:  2500\n",
      "count:  2510\n",
      "count:  2520\n",
      "count:  2530\n",
      "count:  2540\n",
      "count:  2550\n",
      "count:  2560\n",
      "count:  2570\n",
      "count:  2580\n",
      "count:  2590\n",
      "count:  2600\n",
      "count:  2610\n",
      "count:  2620\n",
      "count:  2630\n",
      "count:  2640\n",
      "count:  2650\n",
      "count:  2660\n",
      "count:  2670\n",
      "count:  2680\n",
      "count:  2690\n",
      "count:  2700\n",
      "count:  2710\n",
      "count:  2720\n",
      "count:  2730\n",
      "count:  2740\n",
      "count:  2750\n",
      "count:  2760\n",
      "count:  2770\n",
      "count:  2780\n",
      "count:  2790\n",
      "count:  2800\n",
      "count:  2810\n",
      "count:  2820\n",
      "count:  2830\n",
      "count:  2840\n",
      "count:  2850\n",
      "count:  2860\n",
      "count:  2870\n",
      "count:  2880\n",
      "count:  2890\n",
      "count:  2900\n",
      "count:  2910\n",
      "count:  2920\n",
      "count:  2930\n",
      "count:  2940\n",
      "count:  2950\n",
      "count:  2960\n",
      "count:  2970\n",
      "count:  2980\n",
      "count:  2990\n",
      "count:  3000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a9e61e0ace22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLayerNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0moutput_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetUnconnectedOutLayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Process the detected objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Specify the classes to detect (in this case, 'bat')\n",
    "classes = [\"baseball bat\"]\n",
    "\n",
    "# Set the input image size (YOLOv3 accepts images in multiples of 32)\n",
    "input_width = 416\n",
    "input_height = 416\n",
    "\n",
    "# Loop through each frame in the folder\n",
    "frame_folder = \"C:/Users/Yash/output_dir\"\n",
    "frame_files = glob.glob(frame_folder + \"/*.jpg\")  # Modify the file extension if needed\n",
    "print(len(frame_files))\n",
    "frames_with_bat = []\n",
    "count=0\n",
    "for frame_file in frame_files:\n",
    "    # Load the image\n",
    "    count+=1\n",
    "    if(count%10==0):\n",
    "        print('count: ',count)\n",
    "    frame = cv2.imread(frame_file)\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Create a blob from the image and perform a forward pass\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (input_width, input_height), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Process the detected objects\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Adjust the confidence threshold if needed\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append(detection[0:4] * np.array([width, height, width, height]))\n",
    "\n",
    "    # Check if any bat is detected in the current frame\n",
    "    if len(boxes) > 0:\n",
    "        frames_with_bat.append(frame_file)\n",
    "\n",
    "print(\"Frames with bat:\", frames_with_bat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000-len(frames_with_bat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1175\n",
      "80.66639018058777\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fabca2907a09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytube\n",
    "import time\n",
    "tic=time.time()\n",
    "\n",
    "def detect_pitch_in_video(video_url):\n",
    "    # Load video\n",
    "    video = pytube.YouTube(video_url)\n",
    "    stream = video.streams.get_by_itag(22)\n",
    "    file = stream.download()    \n",
    "    video_capture = cv2.VideoCapture(file)\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Initialize variables\n",
    "    pitch_detected = False\n",
    "    pitch_timestamps = []\n",
    "    frames=[]\n",
    "\n",
    "    while True:\n",
    "        # Read frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply thresholding to segment the pitch\n",
    "        _, thresholded = cv2.threshold(gray_frame, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Iterate through the contours\n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a polygon\n",
    "            approx = cv2.approxPolyDP(contour, 0.05 * cv2.arcLength(contour, True), True)\n",
    "\n",
    "            # If the polygon has 4 sides (a rectangular shape)\n",
    "            if len(approx) == 4:\n",
    "                # Calculate the area of the contour\n",
    "                contour_area = cv2.contourArea(approx)\n",
    "\n",
    "                # If the area is within a certain range, consider it as the pitch\n",
    "                if 20000 < contour_area < 80000:\n",
    "                    pitch_detected = True\n",
    "\n",
    "        # If pitch is detected\n",
    "        if pitch_detected:\n",
    "            # Get current frame timestamp\n",
    "#             timestamp = video_capture.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "#             pitch_timestamps.append(timestamp)\n",
    "            f_no = video_capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            frames.append(f_no)\n",
    "            pitch_detected = False  # Reset pitch detection flag\n",
    "            \n",
    "    # Release video capture and close windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#     return pitch_timestamps\n",
    "    return frames\n",
    "\n",
    "# Usage\n",
    "video_url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "timestamps = detect_pitch_in_video(video_url)\n",
    "print(len(timestamps))\n",
    "print(time.time()-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "t.append(timestamps[0])\n",
    "j=0\n",
    "for i in range(1,len(timestamps)):\n",
    "    if(timestamps[i]-t[j]>=25):\n",
    "        t.append(timestamps[i])\n",
    "        j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4422545433044434\n",
      "56910.5\n"
     ]
    }
   ],
   "source": [
    "import pytube\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "def if_pitch(frame,i):\n",
    "    \n",
    "    pitch_detected=False\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply thresholding to segment the pitch\n",
    "    _, thresholded = cv2.threshold(gray_frame, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate through the contours\n",
    "    for contour in contours:\n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(contour, 0.05 * cv2.arcLength(contour, True), True)\n",
    "        \n",
    "        # If the polygon has 4 sides (a rectangular shape)\n",
    "        if len(approx) == 4:\n",
    "            # Calculate the area of the contour\n",
    "            contour_area = cv2.contourArea(approx)\n",
    "\n",
    "            # If the area is within a certain range, consider it as the pitch\n",
    "            if 20000 < contour_area < 80000:\n",
    "                print(contour_area)\n",
    "                return True\n",
    "    return (pitch_detected)\n",
    "tic=time.time()\n",
    "video_url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "video = pytube.YouTube(video_url)\n",
    "stream = video.streams.get_by_itag(22)\n",
    "file = stream.download()    \n",
    "video_capture = cv2.VideoCapture(file)\n",
    "temp=[198]\n",
    "for i in temp:    \n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = video_capture.read()\n",
    "    print(time.time()-tic)\n",
    "    if(if_pitch(frame,i)):\n",
    "        pass\n",
    "#         path=os.path.join(\"output_dir\", \"frame_\" + str(i) + \".jpg\")\n",
    "#         cv2.imwrite(path, frame)\n",
    "# ______---------------------------_________________________-------------------\n",
    "# ______---------------------------_________________________-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def is_pitch(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to segment the pitch\n",
    "    _, thresholded = cv2.threshold(gray_frame, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate through the contours\n",
    "    for contour in contours:\n",
    "        # Calculate the area of the contour\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "\n",
    "        # If the area is within a certain range, consider it as the pitch\n",
    "        if 20000 < contour_area < 80000:\n",
    "            # Draw a rectangle around the detected pitch\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "video_url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "video = pytube.YouTube(video_url)\n",
    "stream = video.streams.get_by_itag(22)\n",
    "file = stream.download()    \n",
    "video_capture = cv2.VideoCapture(file)\n",
    "isFrame=[]\n",
    "ifFrame=[]\n",
    "for i in t:    \n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = video_capture.read()\n",
    "    if(is_pitch(frame)):\n",
    "#         path=os.path.join(\"output_dir\", \"frame_\" + str(i) + \".jpg\")\n",
    "#         cv2.imwrite(path, frame)\n",
    "        isFrame.append(i)\n",
    "    if(if_pitch(frame)):\n",
    "        ifFrame.append(i)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198.0,\n",
       " 643.0,\n",
       " 668.0,\n",
       " 693.0,\n",
       " 792.0,\n",
       " 919.0,\n",
       " 994.0,\n",
       " 1068.0,\n",
       " 1778.0,\n",
       " 1926.0,\n",
       " 2032.0,\n",
       " 2959.0,\n",
       " 3304.0,\n",
       " 3540.0,\n",
       " 3919.0,\n",
       " 4441.0,\n",
       " 4575.0,\n",
       " 4897.0,\n",
       " 5120.0,\n",
       " 5903.0,\n",
       " 6478.0,\n",
       " 7148.0,\n",
       " 7310.0,\n",
       " 7400.0,\n",
       " 9058.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq=[]\n",
    "for i in ifFrame:\n",
    "    if(i not in isFrame):\n",
    "        uniq.append(i)\n",
    "(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.06434059143066\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_clips(video_url, timestamps, output_dir):\n",
    "    # Load video\n",
    "    video = pytube.YouTube(video_url)\n",
    "    stream = video.streams.get_by_itag(22)\n",
    "    file = stream.download()    \n",
    "    video_capture = cv2.VideoCapture(file)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate frame index for each timestamp\n",
    "    frame_indices = [int(timestamp * fps) for timestamp in timestamps]\n",
    "\n",
    "    clips = []\n",
    "\n",
    "    for index in frame_indices:\n",
    "        # Set the frame index\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "\n",
    "        # Read frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extract 1-second clip (10 frames)\n",
    "        clip_frames = [frame]\n",
    "        for _ in range(75):\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            clip_frames.append(frame)\n",
    "        # Create the clip from the frames\n",
    "        clip_path = os.path.join(output_dir, \"clip_\" + str(index) + \".mp4\")\n",
    "        clip = cv2.VideoWriter(clip_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (frame_width, frame_height))\n",
    "        for clip_frame in clip_frames:\n",
    "            clip.write(clip_frame)\n",
    "        clip.release()\n",
    "\n",
    "        clips.append(clip_path)\n",
    "\n",
    "    # Release video capture\n",
    "    video_capture.release()\n",
    "\n",
    "    return clips\n",
    "\n",
    "# Usage\n",
    "video_url = \"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "tic=time.time()\n",
    "clips = extract_clips(video_url, t, \"clips3\")\n",
    "print(time.time()-tic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=AFEZzf9_EHk\"\n",
    "video = pytube.YouTube(url)\n",
    "stream = video.streams.get_by_itag(22)\n",
    "file = stream.download()    \n",
    "video_capture = cv2.VideoCapture(file)\n",
    "\n",
    "# Load the pre-trained YOLO weights and configuration\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "\n",
    "# Specify the output layers\n",
    "output_layers = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(video_capture.isOpened()):\n",
    "    ret,frame=video_capture.read()\n",
    "    if not ret:\n",
    "        break;\n",
    "    count = 0\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id == 0:  # 0 corresponds to 'person' class\n",
    "                count += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the frame\n",
    "frame = cv2.imread('frame_435.jpg')\n",
    "\n",
    "# Load the pre-trained YOLOv3 weights and configuration\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "\n",
    "# Get the output layer names\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Perform person detection\n",
    "blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Extract person bounding box coordinates from the detection output\n",
    "persons = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if class_id == 0 and confidence > 0.5:  # Assuming class 0 corresponds to persons\n",
    "            center_x = int(detection[0] * frame.shape[1])\n",
    "            center_y = int(detection[1] * frame.shape[0])\n",
    "            width = int(detection[2] * frame.shape[1])\n",
    "            height = int(detection[3] * frame.shape[0])\n",
    "            x = int(center_x - width / 2)\n",
    "            y = int(center_y - height / 2)\n",
    "            persons.append([x, y, width, height])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Apply Non-Maximum Suppression to remove redundant detections\n",
    "indices = cv2.dnn.NMSBoxes(persons, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
    "\n",
    "# Calculate distances among the detected persons\n",
    "distances = np.zeros((len(indices), len(indices)))\n",
    "for i in range(len(indices)):\n",
    "    for j in range(len(indices)):\n",
    "        if i != j:\n",
    "            # Calculate the distance between persons i and j (e.g., using centroid distance)\n",
    "            centroid_i = np.array([(persons[i][0] + persons[i][2]) / 2, (persons[i][1] + persons[i][3]) / 2])\n",
    "            centroid_j = np.array([(persons[j][0] + persons[j][2]) / 2, (persons[j][1] + persons[j][3]) / 2])\n",
    "            distances[i][j] = np.linalg.norm(centroid_i - centroid_j)\n",
    "\n",
    "# Draw bounding boxes on the frame (optional)\n",
    "for i in range(len(indices)):\n",
    "    if i in indices:\n",
    "        index = indices[i]\n",
    "        x, y, w, h = persons[index]\n",
    "        confidence = confidences[index]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the frame with bounding boxes (optional)\n",
    "cv2.imshow('Person Detection', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(persons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
